{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   name      10000 non-null  object \n",
      " 1   diameter  10000 non-null  float64\n",
      " 2   weight    10000 non-null  float64\n",
      " 3   red       10000 non-null  int64  \n",
      " 4   green     10000 non-null  int64  \n",
      " 5   blue      10000 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 468.9+ KB\n",
      "None\n",
      "     name  diameter  weight  red  green  blue\n",
      "0  orange      2.96   86.76  172     85     2\n",
      "1  orange      3.91   88.05  166     78     3\n",
      "2  orange      4.42   95.17  156     81     2\n",
      "\n",
      " [0 1]\n",
      "X values : [[2.96 86.76 172 85 2]\n",
      " [3.91 88.05 166 78 3]\n",
      " [4.42 95.17 156 81 2]\n",
      " ...\n",
      " [15.59 256.5 168 82 20]\n",
      " [15.92 260.14 142 72 11]\n",
      " [16.45 261.51 152 74 2]]\n",
      "Y Values :  [0 0 0 0 0]\n",
      "Normalized [[0.07042254 0.00738197 0.66233766 0.55294118 0.01851852]\n",
      " [0.10822832 0.04812589 0.53246753 0.58823529 0.        ]\n",
      " [0.11193477 0.05058655 0.62337662 0.58823529 0.03703704]\n",
      " [0.11267606 0.05150215 0.5974026  0.48235294 0.12962963]] \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8260\\1238132912.py:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  xs : np.array = np.array([1.0, 2.0, 3.0,4.0, 5.0, 6.0], dtype=np.float)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8260\\1238132912.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  ys : np.array = np.array([4.0, 6.0, 8.0, 10.0, 12.0, 14.0], dtype=np.float)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8260\\1238132912.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"name\"][df[\"name\"] == \"orange\"] = 0\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8260\\1238132912.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"name\"][df[\"name\"] == \"grapefruit\"] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 1s 833us/step - loss: 0.6808 - binary_accuracy: 0.6166\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 0s 819us/step - loss: 0.6464 - binary_accuracy: 0.8113\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 0s 897us/step - loss: 0.5960 - binary_accuracy: 0.8980\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 0s 819us/step - loss: 0.5203 - binary_accuracy: 0.9157\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 0s 805us/step - loss: 0.4200 - binary_accuracy: 0.9217\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 0s 819us/step - loss: 0.3308 - binary_accuracy: 0.9249\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 0s 888us/step - loss: 0.2712 - binary_accuracy: 0.9250\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 0s 814us/step - loss: 0.2357 - binary_accuracy: 0.9263\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 0s 874us/step - loss: 0.2150 - binary_accuracy: 0.9286\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 0s 866us/step - loss: 0.2028 - binary_accuracy: 0.9294\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 0s 865us/step - loss: 0.1954 - binary_accuracy: 0.9274\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 0s 828us/step - loss: 0.1907 - binary_accuracy: 0.9281\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 0s 851us/step - loss: 0.1873 - binary_accuracy: 0.9283\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 0s 833us/step - loss: 0.1854 - binary_accuracy: 0.9277\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 0s 856us/step - loss: 0.1841 - binary_accuracy: 0.9296\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 0s 842us/step - loss: 0.1827 - binary_accuracy: 0.9284\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 0s 854us/step - loss: 0.1823 - binary_accuracy: 0.9281\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 0s 892us/step - loss: 0.1817 - binary_accuracy: 0.9266\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - 0s 828us/step - loss: 0.1814 - binary_accuracy: 0.9270\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 0s 819us/step - loss: 0.1813 - binary_accuracy: 0.9279\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 0s 810us/step - loss: 0.1805 - binary_accuracy: 0.9286\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 0s 805us/step - loss: 0.1808 - binary_accuracy: 0.9290\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 0s 819us/step - loss: 0.1803 - binary_accuracy: 0.9277\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 0s 810us/step - loss: 0.1805 - binary_accuracy: 0.9300\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 0s 815us/step - loss: 0.1802 - binary_accuracy: 0.9284\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 0s 819us/step - loss: 0.1802 - binary_accuracy: 0.9276\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 0s 805us/step - loss: 0.1806 - binary_accuracy: 0.9279\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 0s 810us/step - loss: 0.1804 - binary_accuracy: 0.9289\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 0s 874us/step - loss: 0.1805 - binary_accuracy: 0.9283\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 0s 782us/step - loss: 0.1802 - binary_accuracy: 0.9286\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 0s 788us/step - loss: 0.1799 - binary_accuracy: 0.9277\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 0s 789us/step - loss: 0.1801 - binary_accuracy: 0.9277\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 0s 771us/step - loss: 0.1799 - binary_accuracy: 0.9294\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 0s 782us/step - loss: 0.1800 - binary_accuracy: 0.9284\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 0s 776us/step - loss: 0.1798 - binary_accuracy: 0.9284\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 0s 799us/step - loss: 0.1800 - binary_accuracy: 0.9279\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 0s 810us/step - loss: 0.1794 - binary_accuracy: 0.9287\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 0s 819us/step - loss: 0.1794 - binary_accuracy: 0.9271\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 0s 813us/step - loss: 0.1792 - binary_accuracy: 0.9279\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 0s 814us/step - loss: 0.1798 - binary_accuracy: 0.9280\n",
      "Epoch 41/100\n",
      "219/219 [==============================] - 0s 897us/step - loss: 0.1799 - binary_accuracy: 0.9291\n",
      "Epoch 42/100\n",
      "219/219 [==============================] - 0s 876us/step - loss: 0.1798 - binary_accuracy: 0.9277\n",
      "Epoch 43/100\n",
      "219/219 [==============================] - 0s 805us/step - loss: 0.1798 - binary_accuracy: 0.9286\n",
      "Epoch 44/100\n",
      "219/219 [==============================] - 0s 865us/step - loss: 0.1798 - binary_accuracy: 0.9296\n",
      "Epoch 45/100\n",
      "219/219 [==============================] - 0s 860us/step - loss: 0.1796 - binary_accuracy: 0.9291\n",
      "Epoch 46/100\n",
      "219/219 [==============================] - 0s 856us/step - loss: 0.1800 - binary_accuracy: 0.9279\n",
      "Epoch 47/100\n",
      "219/219 [==============================] - 0s 842us/step - loss: 0.1795 - binary_accuracy: 0.9290\n",
      "Epoch 48/100\n",
      "219/219 [==============================] - 0s 842us/step - loss: 0.1795 - binary_accuracy: 0.9281\n",
      "Epoch 49/100\n",
      "219/219 [==============================] - 0s 819us/step - loss: 0.1796 - binary_accuracy: 0.9277\n",
      "Epoch 50/100\n",
      "219/219 [==============================] - 0s 819us/step - loss: 0.1794 - binary_accuracy: 0.9291\n",
      "Epoch 51/100\n",
      "219/219 [==============================] - 0s 785us/step - loss: 0.1794 - binary_accuracy: 0.9301\n",
      "Epoch 52/100\n",
      "219/219 [==============================] - 0s 817us/step - loss: 0.1794 - binary_accuracy: 0.9287\n",
      "Epoch 53/100\n",
      "219/219 [==============================] - 0s 886us/step - loss: 0.1796 - binary_accuracy: 0.9274\n",
      "Epoch 54/100\n",
      "219/219 [==============================] - 0s 828us/step - loss: 0.1793 - binary_accuracy: 0.9277\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - 0s 801us/step - loss: 0.1793 - binary_accuracy: 0.9280\n",
      "Epoch 56/100\n",
      "219/219 [==============================] - 0s 801us/step - loss: 0.1791 - binary_accuracy: 0.9277\n",
      "Epoch 57/100\n",
      "219/219 [==============================] - 0s 805us/step - loss: 0.1794 - binary_accuracy: 0.9277\n",
      "Epoch 58/100\n",
      "219/219 [==============================] - 0s 819us/step - loss: 0.1797 - binary_accuracy: 0.9277\n",
      "Epoch 59/100\n",
      "219/219 [==============================] - 0s 846us/step - loss: 0.1794 - binary_accuracy: 0.9287\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - 0s 837us/step - loss: 0.1798 - binary_accuracy: 0.9277\n",
      "Epoch 61/100\n",
      "219/219 [==============================] - 0s 798us/step - loss: 0.1795 - binary_accuracy: 0.9271\n",
      "Epoch 62/100\n",
      "219/219 [==============================] - 0s 801us/step - loss: 0.1793 - binary_accuracy: 0.9287\n",
      "Epoch 63/100\n",
      "219/219 [==============================] - 0s 796us/step - loss: 0.1797 - binary_accuracy: 0.9286\n",
      "Epoch 64/100\n",
      "219/219 [==============================] - 0s 878us/step - loss: 0.1790 - binary_accuracy: 0.9281\n",
      "Epoch 65/100\n",
      "219/219 [==============================] - 0s 810us/step - loss: 0.1794 - binary_accuracy: 0.9290\n",
      "Epoch 66/100\n",
      "219/219 [==============================] - 0s 805us/step - loss: 0.1794 - binary_accuracy: 0.9284\n",
      "Epoch 67/100\n",
      "219/219 [==============================] - 0s 787us/step - loss: 0.1790 - binary_accuracy: 0.9281\n",
      "Epoch 68/100\n",
      "219/219 [==============================] - 0s 796us/step - loss: 0.1797 - binary_accuracy: 0.9277\n",
      "Epoch 69/100\n",
      "219/219 [==============================] - 0s 798us/step - loss: 0.1792 - binary_accuracy: 0.9274\n",
      "Epoch 70/100\n",
      "219/219 [==============================] - 0s 806us/step - loss: 0.1793 - binary_accuracy: 0.9283\n",
      "Epoch 71/100\n",
      "219/219 [==============================] - 0s 805us/step - loss: 0.1794 - binary_accuracy: 0.9273\n",
      "Epoch 72/100\n",
      "219/219 [==============================] - 0s 796us/step - loss: 0.1790 - binary_accuracy: 0.9287\n",
      "Epoch 73/100\n",
      "219/219 [==============================] - 0s 792us/step - loss: 0.1789 - binary_accuracy: 0.9283\n",
      "Epoch 74/100\n",
      "219/219 [==============================] - 0s 810us/step - loss: 0.1789 - binary_accuracy: 0.9269\n",
      "Epoch 75/100\n",
      "219/219 [==============================] - 0s 878us/step - loss: 0.1792 - binary_accuracy: 0.9291\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - 0s 883us/step - loss: 0.1789 - binary_accuracy: 0.9287\n",
      "Epoch 77/100\n",
      "219/219 [==============================] - 0s 823us/step - loss: 0.1791 - binary_accuracy: 0.9287\n",
      "Epoch 78/100\n",
      "219/219 [==============================] - 0s 807us/step - loss: 0.1789 - binary_accuracy: 0.9294\n",
      "Epoch 79/100\n",
      "219/219 [==============================] - 0s 789us/step - loss: 0.1792 - binary_accuracy: 0.9290\n",
      "Epoch 80/100\n",
      "219/219 [==============================] - 0s 849us/step - loss: 0.1787 - binary_accuracy: 0.9291\n",
      "Epoch 81/100\n",
      "219/219 [==============================] - 0s 842us/step - loss: 0.1788 - binary_accuracy: 0.9290\n",
      "Epoch 82/100\n",
      "219/219 [==============================] - 0s 810us/step - loss: 0.1789 - binary_accuracy: 0.9290\n",
      "Epoch 83/100\n",
      "219/219 [==============================] - 0s 823us/step - loss: 0.1789 - binary_accuracy: 0.9287\n",
      "Epoch 84/100\n",
      "219/219 [==============================] - 0s 796us/step - loss: 0.1788 - binary_accuracy: 0.9286\n",
      "Epoch 85/100\n",
      "219/219 [==============================] - 0s 956us/step - loss: 0.1790 - binary_accuracy: 0.9281\n",
      "Epoch 86/100\n",
      "219/219 [==============================] - 0s 891us/step - loss: 0.1783 - binary_accuracy: 0.9290\n",
      "Epoch 87/100\n",
      "219/219 [==============================] - 0s 877us/step - loss: 0.1790 - binary_accuracy: 0.9287\n",
      "Epoch 88/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.1786 - binary_accuracy: 0.9283\n",
      "Epoch 89/100\n",
      "219/219 [==============================] - 0s 819us/step - loss: 0.1787 - binary_accuracy: 0.9280\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - 0s 801us/step - loss: 0.1787 - binary_accuracy: 0.9279\n",
      "Epoch 91/100\n",
      "219/219 [==============================] - 0s 796us/step - loss: 0.1789 - binary_accuracy: 0.9286\n",
      "Epoch 92/100\n",
      "219/219 [==============================] - 0s 814us/step - loss: 0.1791 - binary_accuracy: 0.9290\n",
      "Epoch 93/100\n",
      "219/219 [==============================] - 0s 821us/step - loss: 0.1790 - binary_accuracy: 0.9289\n",
      "Epoch 94/100\n",
      "219/219 [==============================] - 0s 860us/step - loss: 0.1785 - binary_accuracy: 0.9280\n",
      "Epoch 95/100\n",
      "219/219 [==============================] - 0s 832us/step - loss: 0.1787 - binary_accuracy: 0.9283\n",
      "Epoch 96/100\n",
      "219/219 [==============================] - 0s 820us/step - loss: 0.1785 - binary_accuracy: 0.9299\n",
      "Epoch 97/100\n",
      "219/219 [==============================] - 0s 805us/step - loss: 0.1784 - binary_accuracy: 0.9290\n",
      "Epoch 98/100\n",
      "219/219 [==============================] - 0s 856us/step - loss: 0.1780 - binary_accuracy: 0.9283\n",
      "Epoch 99/100\n",
      "219/219 [==============================] - 0s 842us/step - loss: 0.1786 - binary_accuracy: 0.9276\n",
      "Epoch 100/100\n",
      "219/219 [==============================] - 0s 823us/step - loss: 0.1782 - binary_accuracy: 0.9287\n",
      "<keras.callbacks.History object at 0x0000014C15AD4AC0>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "## Real answer is that the matmethatical model : y = x * 2 + 2\n",
    "xs : np.array = np.array([1.0, 2.0, 3.0,4.0, 5.0, 6.0], dtype=np.float)\n",
    "ys : np.array = np.array([4.0, 6.0, 8.0, 10.0, 12.0, 14.0], dtype=np.float)\n",
    "\n",
    "model : tf.keras.Sequential = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(), loss=tf.keras.losses.MeanSquaredError())\n",
    "#model.fit(xs,ys, epochs=150)\n",
    "\n",
    "\n",
    "#print(model.predict([10.0]))\n",
    "\n",
    "#************************************************************************** Multiple Layer Perceptron ( Binary Classification )  ********************************************\n",
    "\n",
    "df : pd.DataFrame = pd.read_csv(\"citrus.csv\")\n",
    "\n",
    "\n",
    "print(df.info())\n",
    "print(df.head(3))\n",
    "model : tf.keras.Sequential = tf.keras.Sequential([\n",
    "           keras.layers.Dense(units=1, input_shape=[1]),\n",
    "           keras.layers.Dense(units=8),\n",
    "           keras.layers.Dense(units=1) ]\n",
    ")\n",
    "\n",
    "df[\"name\"][df[\"name\"] == \"orange\"] = 0\n",
    "df[\"name\"][df[\"name\"] == \"grapefruit\"] = 1\n",
    "\n",
    "print(\"\\n\",df[\"name\"].unique())\n",
    "\n",
    "#### Convert it to np.arr < Because it sucks with dataframe >\n",
    "dataset : np.array = df.values\n",
    "############# Only take the feature & label #######################\n",
    "X : np.array = dataset[:, 1:]\n",
    "Y : np.array = dataset[:, 0]\n",
    "print(\"X values :\", X)\n",
    "print(\"Y Values : \",Y[:5])\n",
    "#######################################################################\n",
    "\n",
    "\n",
    "############# Normalisasi #######################\n",
    "min_max_scaler_obj : preprocessing.MinMaxScaler = preprocessing.MinMaxScaler()\n",
    "x_normalized :  np.array = min_max_scaler_obj.fit_transform(X)\n",
    "print(\"Normalized %s \" %(x_normalized[1:5]))\n",
    "#######################################################################\n",
    "\n",
    "############# Split Dataset #######################\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_normalized, Y, test_size=0.3,random_state=0 )\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "############ Modelling #######################\n",
    "neuron_1 : int = 32\n",
    "neuron_2 : int = 1\n",
    "\n",
    "model : tf.keras.Sequential = tf.keras.Sequential([\n",
    "    keras.layers.Dense(neuron_1, \n",
    "                       activation=keras.activations.relu,\n",
    "                       input_shape=(x_normalized.shape[1], )), # (5,)\n",
    "    keras.layers.Dense(neuron_1,\n",
    "                       activation=keras.activations.relu),\n",
    "    keras.layers.Dense(neuron_2,\n",
    "                       activation=keras.activations.sigmoid)\n",
    "],name=\"Model_Ampas\")\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "############ Compilling #######################\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    metrics=[\n",
    "    tf.keras.metrics.BinaryAccuracy()\n",
    "    ]\n",
    ")\n",
    "#history = model.fit(x_train, y_train,epochs=100)\n",
    "#print(history)\n",
    "#model.evaluate(x_test,y_test)\n",
    "# [Loss, Acc]\n",
    "#######################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             150 non-null    int64  \n",
      " 1   SepalLengthCm  150 non-null    float64\n",
      " 2   SepalWidthCm   150 non-null    float64\n",
      " 3   PetalLengthCm  150 non-null    float64\n",
      " 4   PetalWidthCm   150 non-null    float64\n",
      " 5   Species        150 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n",
      "None\n",
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Iris-setosa  \\\n",
      "0              5.1           3.5            1.4           0.2            1   \n",
      "1              4.9           3.0            1.4           0.2            1   \n",
      "2              4.7           3.2            1.3           0.2            1   \n",
      "3              4.6           3.1            1.5           0.2            1   \n",
      "4              5.0           3.6            1.4           0.2            1   \n",
      "..             ...           ...            ...           ...          ...   \n",
      "145            6.7           3.0            5.2           2.3            0   \n",
      "146            6.3           2.5            5.0           1.9            0   \n",
      "147            6.5           3.0            5.2           2.0            0   \n",
      "148            6.2           3.4            5.4           2.3            0   \n",
      "149            5.9           3.0            5.1           1.8            0   \n",
      "\n",
      "     Iris-versicolor  Iris-virginica  \n",
      "0                  0               0  \n",
      "1                  0               0  \n",
      "2                  0               0  \n",
      "3                  0               0  \n",
      "4                  0               0  \n",
      "..               ...             ...  \n",
      "145                0               1  \n",
      "146                0               1  \n",
      "147                0               1  \n",
      "148                0               1  \n",
      "149                0               1  \n",
      "\n",
      "[150 rows x 7 columns]\n",
      "(150, 4)\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1236 - categorical_accuracy: 0.3619\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0809 - categorical_accuracy: 0.6381\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0472 - categorical_accuracy: 0.6476\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0134 - categorical_accuracy: 0.6571\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9819 - categorical_accuracy: 0.6952\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9495 - categorical_accuracy: 0.6762\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9154 - categorical_accuracy: 0.6952\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8809 - categorical_accuracy: 0.6952\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8448 - categorical_accuracy: 0.6952\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8073 - categorical_accuracy: 0.6952\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7699 - categorical_accuracy: 0.6952\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7320 - categorical_accuracy: 0.6952\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6951 - categorical_accuracy: 0.6952\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6580 - categorical_accuracy: 0.6952\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6238 - categorical_accuracy: 0.6952\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5936 - categorical_accuracy: 0.6952\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5655 - categorical_accuracy: 0.6952\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5403 - categorical_accuracy: 0.6952\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5197 - categorical_accuracy: 0.6952\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5011 - categorical_accuracy: 0.6952\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4853 - categorical_accuracy: 0.6952\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4708 - categorical_accuracy: 0.6952\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4583 - categorical_accuracy: 0.6952\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4476 - categorical_accuracy: 0.7333\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4376 - categorical_accuracy: 0.7524\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4278 - categorical_accuracy: 0.7619\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4193 - categorical_accuracy: 0.7524\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4120 - categorical_accuracy: 0.7524\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4033 - categorical_accuracy: 0.7714\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3964 - categorical_accuracy: 0.7714\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3889 - categorical_accuracy: 0.7714\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3827 - categorical_accuracy: 0.7714\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3758 - categorical_accuracy: 0.7714\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3703 - categorical_accuracy: 0.8476\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3592 - categorical_accuracy: 0.9333\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3520 - categorical_accuracy: 0.9333\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3457 - categorical_accuracy: 0.9429\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3418 - categorical_accuracy: 0.9619\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3310 - categorical_accuracy: 0.9524\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3218 - categorical_accuracy: 0.9333\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3148 - categorical_accuracy: 0.9333\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3075 - categorical_accuracy: 0.9333\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3012 - categorical_accuracy: 0.9429\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2935 - categorical_accuracy: 0.9619\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2899 - categorical_accuracy: 0.9524\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2784 - categorical_accuracy: 0.9429\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2719 - categorical_accuracy: 0.9619\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2673 - categorical_accuracy: 0.9619\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2601 - categorical_accuracy: 0.9619\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2503 - categorical_accuracy: 0.9619\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2476 - categorical_accuracy: 0.9429\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2411 - categorical_accuracy: 0.9429\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2342 - categorical_accuracy: 0.9524\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2280 - categorical_accuracy: 0.9619\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2248 - categorical_accuracy: 0.9714\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2176 - categorical_accuracy: 0.9524\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2108 - categorical_accuracy: 0.9619\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2037 - categorical_accuracy: 0.9524\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2001 - categorical_accuracy: 0.9619\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1933 - categorical_accuracy: 0.9619\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1891 - categorical_accuracy: 0.9619\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1835 - categorical_accuracy: 0.9619\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1815 - categorical_accuracy: 0.9619\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1765 - categorical_accuracy: 0.9619\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1719 - categorical_accuracy: 0.9714\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1669 - categorical_accuracy: 0.9619\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1675 - categorical_accuracy: 0.9524\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1620 - categorical_accuracy: 0.9619\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1557 - categorical_accuracy: 0.9714\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1548 - categorical_accuracy: 0.9619\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1494 - categorical_accuracy: 0.9619\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1477 - categorical_accuracy: 0.9714\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1433 - categorical_accuracy: 0.9714\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1428 - categorical_accuracy: 0.9619\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1394 - categorical_accuracy: 0.9619\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1375 - categorical_accuracy: 0.9714\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1347 - categorical_accuracy: 0.9714\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1314 - categorical_accuracy: 0.9619\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1284 - categorical_accuracy: 0.9619\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1280 - categorical_accuracy: 0.9714\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1240 - categorical_accuracy: 0.9714\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1290 - categorical_accuracy: 0.9619\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1275 - categorical_accuracy: 0.9619\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.1198 - categorical_accuracy: 0.9619\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1193 - categorical_accuracy: 0.9619\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1167 - categorical_accuracy: 0.9619\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1164 - categorical_accuracy: 0.9619\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1150 - categorical_accuracy: 0.9619\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1128 - categorical_accuracy: 0.9619\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1112 - categorical_accuracy: 0.9619\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1088 - categorical_accuracy: 0.9619\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1076 - categorical_accuracy: 0.9619\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1067 - categorical_accuracy: 0.9619\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1062 - categorical_accuracy: 0.9619\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1060 - categorical_accuracy: 0.9619\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1032 - categorical_accuracy: 0.9619\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1006 - categorical_accuracy: 0.9619\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1030 - categorical_accuracy: 0.9619\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1019 - categorical_accuracy: 0.9619\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0980 - categorical_accuracy: 0.9619\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0744 - categorical_accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07435642927885056, 0.9777777791023254]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#************************************************************************** Multiple Layer Perceptron ( Multiple classes Classification )  ********************************************\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "\n",
    "######################Preprocessing Basic Bruh################\n",
    "\n",
    "df : pd.DataFrame = pd.read_csv(\"Iris.csv\")\n",
    "print(df.info())\n",
    "\n",
    "df : pd.DataFrame = df.drop(\"Id\",axis=1)\n",
    "\n",
    "category : pd.DataFrame = pd.get_dummies(df[\"Species\"])\n",
    "\n",
    "df_new : pd.DataFrame = pd.concat([df, category], axis=1)\n",
    "df_new = df_new.drop(\"Species\", axis=1)\n",
    "print(df_new)\n",
    "\n",
    "####################### Convert to np and then go to the Normalization more !###########################\n",
    "\n",
    "np_data : np.array = df_new.values\n",
    "X = np_data[:, :4]\n",
    "Y = np_data[:, 4:] # Col 5,6,7\n",
    "\n",
    "# Normalizing\n",
    "min_max_scale : preprocessing.MinMaxScaler =  preprocessing.MinMaxScaler() # Information of Transformation is in here !\n",
    "x_normalized : np.array = min_max_scale.fit_transform(X)\n",
    "print(x_normalized.shape)\n",
    "\n",
    "\n",
    "## SPLIT the dataset\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_normalized, Y, test_size=0.3, random_state=1)\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "####################### Modelling   ###########################\n",
    "neuron_1 : int = 64\n",
    "neuron_2 : int = 3 # Representing the output class\n",
    "model : tf.keras.Sequential = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=neuron_1, activation=tf.keras.activations.relu, input_shape=(x_normalized.shape[1],)), #(4,)\n",
    "        tf.keras.layers.Dense(units=neuron_1, activation=tf.keras.activations.relu),\n",
    "        tf.keras.layers.Dense(units=neuron_2, activation=tf.keras.activations.softmax)\n",
    "        \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy()\n",
    "    ]\n",
    ")\n",
    "hist = model.fit(x_train,y_train, epochs=100)\n",
    "model.evaluate(x_test,y_test)\n",
    "#######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0863 - categorical_accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08628230541944504, 0.9777777791023254]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSiens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a28ba3cb4290f43887b639e4d902048abae311a128a19465268895f960a8f8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
